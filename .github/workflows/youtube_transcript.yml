name: YouTube Transcript Agent V2

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube URL (shorts, reels, regular videos)'
        required: true
        default: 'https://youtube.com/shorts/C2Dl6P7diHw'
      use_whisper:
        description: 'Use Whisper fallback if no captions'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      log_to_supabase:
        description: 'Save to Supabase learning sessions'
        required: false
        default: 'true'
        type: choice
        options:
          - 'true'
          - 'false'
      whisper_model:
        description: 'Whisper model size (base=fast, small=better)'
        required: false
        default: 'base'
        type: choice
        options:
          - 'base'
          - 'small'
          - 'medium'

env:
  SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co

jobs:
  extract-transcript:
    runs-on: ubuntu-latest
    timeout-minutes: 30
    
    steps:
      - name: Checkout Life OS
        uses: actions/checkout@v4
        
      - name: Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Setup FFmpeg (for Whisper fallback)
        if: ${{ github.event.inputs.use_whisper == 'true' }}
        uses: FedericoCarboni/setup-ffmpeg@v3
          
      - name: Install dependencies
        run: |
          pip install yt-dlp requests
          
          # Only install Whisper if enabled (saves ~3min on install)
          if [ "${{ github.event.inputs.use_whisper }}" == "true" ]; then
            echo "üì¶ Installing Whisper (fallback enabled)..."
            pip install openai-whisper torch --extra-index-url https://download.pytorch.org/whl/cpu
          fi
          
      - name: üé¨ Extract YouTube Transcript
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          USE_WHISPER: ${{ github.event.inputs.use_whisper }}
          WHISPER_MODEL: ${{ github.event.inputs.whisper_model }}
          LOG_TO_SUPABASE: ${{ github.event.inputs.log_to_supabase }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
        run: |
          python3 << 'PYEOF'
          import os
          import re
          import json
          import glob
          import subprocess
          from datetime import datetime

          # ============================================================
          # CONFIG
          # ============================================================
          video_url = os.environ.get('VIDEO_URL', '')
          use_whisper = os.environ.get('USE_WHISPER', 'true') == 'true'
          whisper_model = os.environ.get('WHISPER_MODEL', 'base')
          log_to_supabase = os.environ.get('LOG_TO_SUPABASE', 'true') == 'true'
          supabase_url = os.environ.get('SUPABASE_URL', 'https://mocerqjnksmhcjzxrewo.supabase.co')
          supabase_key = os.environ.get('SUPABASE_KEY', '')

          print("=" * 60)
          print("üé¨ YouTube Transcript Agent V2")
          print("=" * 60)
          print(f"üì∫ URL: {video_url}")
          print(f"üé§ Whisper fallback: {use_whisper}")
          print(f"üì§ Supabase logging: {log_to_supabase}")

          # ============================================================
          # PARSE VIDEO ID
          # ============================================================
          def extract_video_id(url):
              patterns = [
                  r'shorts/([a-zA-Z0-9_-]{11})',
                  r'(?:v=|/v/)([a-zA-Z0-9_-]{11})',
                  r'youtu\.be/([a-zA-Z0-9_-]{11})',
                  r'embed/([a-zA-Z0-9_-]{11})',
              ]
              for pattern in patterns:
                  match = re.search(pattern, url)
                  if match:
                      return match.group(1)
              return None

          video_id = extract_video_id(video_url)
          if not video_id:
              print("‚ùå Invalid YouTube URL")
              exit(1)

          is_short = '/shorts/' in video_url.lower()
          print(f"‚úÖ Video ID: {video_id}")
          print(f"üì± Type: {'Shorts/Reel' if is_short else 'Regular video'}")

          # ============================================================
          # STRATEGY 1: CAPTIONS (FREE, INSTANT)
          # ============================================================
          print("\nüéØ Strategy 1: YouTube Captions (FREE)")
          
          transcript = None
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0}
          source = "none"
          language = "unknown"

          try:
              # Download subtitles with yt-dlp
              cmd = [
                  'yt-dlp',
                  '--skip-download',
                  '--write-subs',
                  '--write-auto-subs',
                  '--sub-lang', 'en,en-US,en-GB,iw,he',
                  '--convert-subs', 'vtt',
                  '--print-json',
                  '--no-warnings',
                  '-o', 'caption.%(ext)s',
                  video_url
              ]
              
              result = subprocess.run(cmd, capture_output=True, text=True, timeout=60)
              
              # Parse metadata
              for line in result.stdout.strip().split('\n'):
                  if line.startswith('{'):
                      try:
                          metadata = json.loads(line)
                          break
                      except:
                          continue
              
              print(f"üìù Title: {metadata.get('title', 'Unknown')[:60]}")
              print(f"üë§ Channel: {metadata.get('channel', 'Unknown')}")
              print(f"‚è±Ô∏è Duration: {metadata.get('duration', 0)}s")
              
              # Find subtitle file
              vtt_files = glob.glob('caption*.vtt')
              
              if vtt_files:
                  with open(vtt_files[0], 'r', encoding='utf-8') as f:
                      content = f.read()
                  
                  # Parse VTT to plain text
                  lines = content.split('\n')
                  text_lines = []
                  for line in lines:
                      line = line.strip()
                      if not line or line.startswith('WEBVTT') or '-->' in line:
                          continue
                      if line.startswith('Kind:') or line.startswith('Language:'):
                          continue
                      if re.match(r'^\d+$', line):
                          continue
                      line = re.sub(r'<[^>]+>', '', line)
                      if text_lines and line == text_lines[-1]:
                          continue
                      text_lines.append(line)
                  
                  transcript = ' '.join(text_lines)
                  transcript = re.sub(r'\s+', ' ', transcript).strip()
                  
                  if len(transcript) > 50:
                      source = "youtube_captions"
                      language = "en"
                      print(f"‚úÖ Captions extracted: {len(transcript)} chars")
                  
                  # Cleanup
                  for f in vtt_files:
                      try:
                          os.remove(f)
                      except:
                          pass
              else:
                  print("‚ö†Ô∏è No caption files found")
                  
          except Exception as e:
              print(f"‚ö†Ô∏è Caption extraction failed: {e}")

          # ============================================================
          # STRATEGY 2: WHISPER (FALLBACK)
          # ============================================================
          if (not transcript or len(transcript) < 50) and use_whisper:
              print("\nüéØ Strategy 2: Whisper Transcription (Fallback)")
              
              try:
                  import whisper
                  
                  # Download audio
                  print("üîä Downloading audio...")
                  cmd = [
                      'yt-dlp', '-x', '--audio-format', 'mp3',
                      '-o', 'audio.%(ext)s', '--no-warnings', video_url
                  ]
                  subprocess.run(cmd, capture_output=True, timeout=300)
                  
                  audio_files = glob.glob('audio.*')
                  if audio_files:
                      audio_file = audio_files[0]
                      print(f"‚úÖ Audio: {audio_file}")
                      
                      print(f"üé§ Transcribing with Whisper {whisper_model}...")
                      model = whisper.load_model(whisper_model)
                      result = model.transcribe(audio_file, language=None)
                      
                      transcript = result['text']
                      language = result.get('language', 'unknown')
                      source = f"whisper_{whisper_model}"
                      
                      print(f"‚úÖ Whisper complete: {len(transcript)} chars, lang={language}")
                      
                      # Cleanup
                      for f in audio_files:
                          try:
                              os.remove(f)
                          except:
                              pass
                  else:
                      print("‚ùå Audio download failed")
                      
              except Exception as e:
                  print(f"‚ùå Whisper failed: {e}")

          # ============================================================
          # BUILD RESULT
          # ============================================================
          if not transcript:
              transcript = ""
              print("\n‚ùå No transcript available")

          result = {
              "video_id": video_id,
              "video_url": video_url,
              "is_short": is_short,
              "title": metadata.get('title', 'Unknown'),
              "channel": metadata.get('channel', 'Unknown'),
              "duration_seconds": metadata.get('duration', 0),
              "view_count": metadata.get('view_count', 0),
              "transcript": transcript[:100000],
              "transcript_source": source,
              "language": language,
              "word_count": len(transcript.split()) if transcript else 0,
              "char_count": len(transcript),
              "timestamp": datetime.now().isoformat()
          }

          # Save to file
          with open('transcript.json', 'w', encoding='utf-8') as f:
              json.dump(result, f, indent=2, ensure_ascii=False)

          # ============================================================
          # PRINT SUMMARY
          # ============================================================
          print("\n" + "=" * 60)
          print("üìä RESULT SUMMARY")
          print("=" * 60)
          print(f"   Title: {result['title'][:50]}...")
          print(f"   Channel: {result['channel']}")
          print(f"   Duration: {result['duration_seconds'] // 60}m {result['duration_seconds'] % 60}s")
          print(f"   Source: {result['transcript_source']}")
          print(f"   Language: {result['language']}")
          print(f"   Words: {result['word_count']}")

          print("\nüìù TRANSCRIPT:")
          print("-" * 60)
          if transcript:
              print(transcript[:5000])
              if len(transcript) > 5000:
                  print(f"\n... [truncated, {len(transcript)} total chars]")
          else:
              print("(no transcript)")

          # ============================================================
          # LOG TO SUPABASE
          # ============================================================
          if log_to_supabase and supabase_key and transcript:
              try:
                  import requests
                  
                  insight_data = {
                      "user_id": 1,
                      "insight_type": "youtube_transcript",
                      "title": f"YT: {result['title'][:80]}",
                      "description": json.dumps({
                          "video_id": video_id,
                          "video_url": video_url,
                          "channel": result['channel'],
                          "duration_min": result['duration_seconds'] // 60,
                          "source": source,
                          "language": language,
                          "words": result['word_count'],
                          "is_short": is_short,
                          "transcript_preview": transcript[:3000]
                      }, ensure_ascii=False),
                      "priority": 2
                  }
                  
                  headers = {
                      "apikey": supabase_key,
                      "Authorization": f"Bearer {supabase_key}",
                      "Content-Type": "application/json",
                      "Prefer": "return=minimal"
                  }
                  
                  response = requests.post(
                      f"{supabase_url}/rest/v1/insights",
                      headers=headers,
                      json=insight_data,
                      timeout=30
                  )
                  
                  print(f"\nüì§ Logged to Supabase: {response.status_code}")
                  
              except Exception as e:
                  print(f"\n‚ö†Ô∏è Supabase logging failed: {e}")

          print("\n‚úÖ Complete!")
          PYEOF
          
      - name: üì§ Upload transcript artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: transcript-${{ github.run_id }}
          path: |
            transcript.json
          retention-days: 30
          if-no-files-found: warn
          
      - name: üìã Output transcript summary
        if: always()
        run: |
          if [ -f transcript.json ]; then
            echo "### üì∫ YouTube Transcript Extracted" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "| Field | Value |" >> $GITHUB_STEP_SUMMARY
            echo "|-------|-------|" >> $GITHUB_STEP_SUMMARY
            echo "| Video ID | $(cat transcript.json | python3 -c 'import sys,json; print(json.load(sys.stdin).get("video_id","N/A"))') |" >> $GITHUB_STEP_SUMMARY
            echo "| Title | $(cat transcript.json | python3 -c 'import sys,json; print(json.load(sys.stdin).get("title","N/A")[:50])') |" >> $GITHUB_STEP_SUMMARY
            echo "| Source | $(cat transcript.json | python3 -c 'import sys,json; print(json.load(sys.stdin).get("transcript_source","N/A"))') |" >> $GITHUB_STEP_SUMMARY
            echo "| Words | $(cat transcript.json | python3 -c 'import sys,json; print(json.load(sys.stdin).get("word_count",0))') |" >> $GITHUB_STEP_SUMMARY
            echo "" >> $GITHUB_STEP_SUMMARY
            echo "**Transcript Preview:**" >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
            cat transcript.json | python3 -c 'import sys,json; t=json.load(sys.stdin).get("transcript",""); print(t[:1000] + "..." if len(t)>1000 else t)'  >> $GITHUB_STEP_SUMMARY
            echo '```' >> $GITHUB_STEP_SUMMARY
          fi
