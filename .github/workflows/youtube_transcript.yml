name: Extract YouTube Transcript

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube video URL'
        required: true
        default: 'https://youtube.com/watch?v=Ea1EpD-4sUU'
      log_to_supabase:
        description: 'Save to Supabase learning sessions'
        required: false
        default: 'true'

jobs:
  extract:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        
      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install dependencies
        run: |
          pip install youtube-transcript-api yt-dlp requests
          
      - name: Extract transcript with multiple methods
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          LOG_TO_SUPABASE: ${{ github.event.inputs.log_to_supabase }}
        run: |
          python3 << 'PYEOF'
          import os
          import re
          import json
          import requests
          import subprocess

          video_url = os.environ.get('VIDEO_URL', '')
          supabase_url = os.environ.get('SUPABASE_URL', '')
          supabase_key = os.environ.get('SUPABASE_KEY', '')
          log_to_supabase = os.environ.get('LOG_TO_SUPABASE', 'true') == 'true'

          # Extract video ID
          match = re.search(r'(?:v=|/)([a-zA-Z0-9_-]{11})', video_url)
          if not match:
              print("‚ùå Invalid YouTube URL")
              exit(1)

          video_id = match.group(1)
          print(f"üì∫ Video ID: {video_id}")

          # Get video metadata
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0}
          try:
              result = subprocess.run(
                  ['yt-dlp', '--print-json', '--skip-download', '--no-warnings', video_url],
                  capture_output=True, text=True, timeout=120
              )
              if result.returncode == 0 and result.stdout.strip():
                  metadata = json.loads(result.stdout)
                  print(f"üìù Title: {metadata.get('title', 'Unknown')}")
                  print(f"üë§ Channel: {metadata.get('channel', 'Unknown')}")
                  print(f"‚è±Ô∏è Duration: {metadata.get('duration', 0)} seconds")
                  
                  # Check available subtitles
                  subs = metadata.get('subtitles', {})
                  auto_subs = metadata.get('automatic_captions', {})
                  print(f"üìú Manual subtitles: {list(subs.keys())}")
                  print(f"ü§ñ Auto captions: {list(auto_subs.keys())}")
          except Exception as e:
              print(f"‚ö†Ô∏è Metadata error: {e}")

          # METHOD 1: Try youtube-transcript-api with multiple languages
          full_text = ""
          transcript_source = ""
          
          try:
              from youtube_transcript_api import YouTubeTranscriptApi
              
              # Try different language codes for Hebrew
              lang_codes = ['he', 'iw', 'en', 'en-US', 'a.he', 'a.iw', 'a.en']
              
              for lang in lang_codes:
                  try:
                      transcript = YouTubeTranscriptApi.get_transcript(video_id, languages=[lang])
                      full_text = " ".join([entry['text'] for entry in transcript])
                      transcript_source = f"youtube-transcript-api ({lang})"
                      print(f"‚úÖ Got transcript via {transcript_source}: {len(full_text)} chars")
                      break
                  except Exception as e:
                      print(f"   ‚ùå {lang}: {str(e)[:50]}")
                      continue
                      
              # If no specific language worked, try without language filter
              if not full_text:
                  try:
                      transcript = YouTubeTranscriptApi.get_transcript(video_id)
                      full_text = " ".join([entry['text'] for entry in transcript])
                      transcript_source = "youtube-transcript-api (auto)"
                      print(f"‚úÖ Got transcript via {transcript_source}: {len(full_text)} chars")
                  except Exception as e:
                      print(f"   ‚ùå Auto: {e}")
                      
          except Exception as e:
              print(f"‚ùå youtube-transcript-api failed: {e}")

          # METHOD 2: Try yt-dlp subtitle download
          if not full_text:
              print("\nüîÑ Trying yt-dlp subtitle download...")
              try:
                  # Try Hebrew first, then auto-generated
                  for sub_args in [
                      ['--write-sub', '--sub-lang', 'he,iw,en'],
                      ['--write-auto-sub', '--sub-lang', 'he,iw,en'],
                      ['--write-auto-sub']
                  ]:
                      result = subprocess.run(
                          ['yt-dlp'] + sub_args + ['--skip-download', '--sub-format', 'vtt', '-o', 'subs', video_url],
                          capture_output=True, text=True, timeout=120
                      )
                      
                      # Check for downloaded subtitle files
                      import glob
                      vtt_files = glob.glob('subs*.vtt')
                      if vtt_files:
                          with open(vtt_files[0], 'r', encoding='utf-8') as f:
                              vtt_content = f.read()
                          
                          # Parse VTT - remove timestamps and metadata
                          lines = []
                          for line in vtt_content.split('\n'):
                              line = line.strip()
                              if line and not line.startswith(('WEBVTT', 'Kind:', 'Language:', 'NOTE')) and '-->' not in line and not re.match(r'^\d+$', line):
                                  # Remove HTML tags
                                  clean_line = re.sub(r'<[^>]+>', '', line)
                                  if clean_line:
                                      lines.append(clean_line)
                          
                          full_text = ' '.join(lines)
                          # Remove duplicate consecutive lines (common in VTT)
                          words = full_text.split()
                          deduped = []
                          for i, word in enumerate(words):
                              if i == 0 or word != words[i-1]:
                                  deduped.append(word)
                          full_text = ' '.join(deduped)
                          
                          transcript_source = f"yt-dlp ({vtt_files[0]})"
                          print(f"‚úÖ Got transcript via {transcript_source}: {len(full_text)} chars")
                          break
              except Exception as e:
                  print(f"‚ùå yt-dlp subtitle download failed: {e}")

          # Save output
          if not full_text:
              full_text = "Transcript unavailable - video may not have captions enabled"
              
          output = {
              "video_id": video_id,
              "video_url": video_url,
              "title": metadata.get('title', 'Unknown'),
              "channel": metadata.get('channel', 'Unknown'),
              "duration_seconds": metadata.get('duration', 0),
              "transcript": full_text[:100000],  # Limit size
              "transcript_length": len(full_text),
              "transcript_source": transcript_source or "none"
          }

          with open('transcript.json', 'w', encoding='utf-8') as f:
              json.dump(output, f, indent=2, ensure_ascii=False)

          print(f"\n--- TRANSCRIPT ({transcript_source or 'N/A'}) ---")
          print(full_text[:5000] if len(full_text) > 100 else full_text)

          # Log to Supabase
          if log_to_supabase and supabase_key and len(full_text) > 100:
              try:
                  headers = {
                      "apikey": supabase_key,
                      "Authorization": f"Bearer {supabase_key}",
                      "Content-Type": "application/json"
                  }
                  
                  insight_data = {
                      "user_id": 1,
                      "insight_type": "youtube_transcript",
                      "title": f"Transcript: {metadata.get('title', video_id)[:80]}",
                      "description": json.dumps({
                          "video_id": video_id,
                          "channel": metadata.get('channel', 'Unknown'),
                          "duration_min": metadata.get('duration', 0) // 60,
                          "transcript_chars": len(full_text),
                          "source": transcript_source,
                          "transcript_preview": full_text[:1000]
                      }, ensure_ascii=False),
                      "priority": 2
                  }
                  
                  response = requests.post(
                      f"{supabase_url}/rest/v1/insights",
                      headers=headers,
                      json=insight_data,
                      timeout=30
                  )
                  print(f"\nüì§ Logged to Supabase: {response.status_code}")
              except Exception as e:
                  print(f"‚ö†Ô∏è Supabase logging failed: {e}")

          PYEOF
          
      - name: Upload transcript artifact
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: transcript-${{ github.run_id }}
          path: |
            transcript.json
            subs*.vtt
          retention-days: 30
          if-no-files-found: warn

