name: YouTube Transcript V7

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube URL'
        required: true
        type: string
      category:
        description: 'Category'
        required: false
        default: 'learning'
        type: string

env:
  SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co

jobs:
  transcribe:
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - uses: actions/checkout@v4
      
      - uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: Install Dependencies
        run: |
          pip install youtube-transcript-api yt-dlp httpx requests openai-whisper
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
      - name: Transcribe Video
        id: transcribe
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          CATEGORY: ${{ github.event.inputs.category }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          APIFY_API_TOKEN: ${{ secrets.APIFY_API_TOKEN }}
        run: |
          python3 << 'PYEOF'
          import os, re, json, subprocess, glob, requests, time
          from datetime import datetime, timezone
          
          video_url = os.environ.get('VIDEO_URL', '')
          category = os.environ.get('CATEGORY', 'learning')
          supabase_url = os.environ.get('SUPABASE_URL', '')
          supabase_key = os.environ.get('SUPABASE_KEY', '')
          apify_token = os.environ.get('APIFY_API_TOKEN', '')
          
          print(f"{'='*60}")
          print(f"YOUTUBE TRANSCRIPT V7 (4-Tier)")
          print(f"{'='*60}")
          
          # Extract video ID
          video_id = None
          patterns = [
              r'shorts/([a-zA-Z0-9_-]{11})',
              r'(?:v=|/v/)([a-zA-Z0-9_-]{11})',
              r'youtu\.be/([a-zA-Z0-9_-]{11})',
              r'embed/([a-zA-Z0-9_-]{11})',
              r'/live/([a-zA-Z0-9_-]{11})',
              r'watch\?.*v=([a-zA-Z0-9_-]{11})'
          ]
          for p in patterns:
              m = re.search(p, video_url)
              if m:
                  video_id = m.group(1)
                  break
          
          if not video_id:
              print("Invalid YouTube URL")
              exit(1)
          
          video_type = "short" if '/shorts/' in video_url else "regular"
          print(f"Video: {video_id} ({video_type})")
          
          # Get metadata
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0}
          try:
              r = subprocess.run(['yt-dlp', '--dump-json', '--no-download', video_url], 
                                capture_output=True, text=True, timeout=30)
              if r.returncode == 0:
                  d = json.loads(r.stdout)
                  metadata = {
                      "title": d.get('title', ''),
                      "channel": d.get('channel', '') or d.get('uploader', ''),
                      "duration": d.get('duration', 0)
                  }
                  print(f"Title: {metadata['title'][:60]}")
                  print(f"Channel: {metadata['channel']}")
          except Exception as e:
              print(f"Metadata error: {e}")
          
          transcript = None
          source = "none"
          
          # TIER 1: YouTube Transcript API
          print("\nTIER 1: YouTube Transcript API")
          try:
              from youtube_transcript_api import YouTubeTranscriptApi
              fetched = YouTubeTranscriptApi().fetch(video_id)
              transcript = ' '.join([e.text for e in fetched])
              source = "youtube_api"
              print(f"SUCCESS: {len(transcript)} chars")
          except Exception as e:
              print(f"Failed: {str(e)[:100]}")
          
          # TIER 2: yt-dlp subtitles
          if not transcript or len(transcript) < 20:
              print("\nTIER 2: yt-dlp subtitles")
              try:
                  subprocess.run([
                      'yt-dlp', '--skip-download', 
                      '--write-auto-sub', '--sub-lang', 'en',
                      '-o', f'/tmp/{video_id}', video_url
                  ], capture_output=True, timeout=60)
                  
                  vtt_files = glob.glob(f'/tmp/{video_id}*.vtt')
                  if vtt_files:
                      with open(vtt_files[0]) as f:
                          lines = [l.strip() for l in f 
                                  if l.strip() and not any(x in l for x in ['WEBVTT', '-->', '<'])]
                      transcript = ' '.join(lines)
                      source = "yt-dlp_subs"
                      print(f"SUCCESS: {len(transcript)} chars")
                  else:
                      print("No subtitle files found")
              except Exception as e:
                  print(f"Failed: {e}")
          
          # TIER 3: Whisper
          if not transcript or len(transcript) < 20:
              print("\nTIER 3: Whisper (base)")
              try:
                  os.makedirs('/tmp/audio', exist_ok=True)
                  subprocess.run([
                      'yt-dlp', '-x', '--audio-format', 'mp3',
                      '-o', '/tmp/audio/%(id)s.%(ext)s', video_url
                  ], capture_output=True, timeout=120)
                  
                  audio_files = glob.glob(f'/tmp/audio/{video_id}*')
                  actual_audio = next((f for f in audio_files 
                                      if any(f.endswith(e) for e in ['.mp3','.m4a','.webm','.opus'])), None)
                  
                  if actual_audio and os.path.exists(actual_audio):
                      size = os.path.getsize(actual_audio)
                      if size > 1000:
                          import whisper
                          model = whisper.load_model("base")
                          result = model.transcribe(actual_audio)
                          transcript = result["text"].strip()
                          source = "whisper_base"
                          print(f"SUCCESS: {len(transcript)} chars")
              except Exception as e:
                  print(f"Failed: {e}")
          
          # TIER 4: Apify
          if (not transcript or len(transcript) < 20) and apify_token:
              print("\nTIER 4: Apify")
              try:
                  run_response = requests.post(
                      f"https://api.apify.com/v2/acts/karamelo~youtube-transcripts/runs?token={apify_token}&waitForFinish=120",
                      headers={"Content-Type": "application/json"},
                      json={"urls": [video_url], "output_format": "captions_text"},
                      timeout=130
                  )
                  
                  if run_response.status_code == 201:
                      run_data = run_response.json()
                      dataset_id = run_data.get('data', {}).get('defaultDatasetId')
                      
                      if dataset_id:
                          time.sleep(5)
                          items_response = requests.get(
                              f"https://api.apify.com/v2/datasets/{dataset_id}/items?token={apify_token}",
                              timeout=30
                          )
                          
                          if items_response.status_code == 200:
                              items = items_response.json()
                              if items:
                                  captions = items[0].get('captions', [])
                                  if captions:
                                      raw_text = ' '.join(captions)
                                      transcript = raw_text.replace('&#39;', "'").replace('&amp;', '&')
                                      source = "apify"
                                      print(f"SUCCESS: {len(transcript)} chars")
              except Exception as e:
                  print(f"Failed: {e}")
          
          if not transcript or len(transcript) < 20:
              transcript = "Transcript unavailable"
              source = "failed"
          
          print(f"\n{'='*60}")
          print(f"RESULT: {source} | {len(transcript)} chars")
          print(f"{'='*60}")
          print(f"\n{transcript[:1000]}...")
          
          # Save to Supabase
          if supabase_key and source != "failed":
              try:
                  headers = {
                      "apikey": supabase_key,
                      "Authorization": f"Bearer {supabase_key}",
                      "Content-Type": "application/json",
                      "Prefer": "return=minimal"
                  }
                  
                  insight = {
                      "user_id": 1,
                      "insight_type": "youtube_transcript",
                      "title": f"{metadata['title'][:80]}",
                      "content": transcript[:10000],
                      "category": category,
                      "source": f"youtube_v7_{source}",
                      "priority": 2,
                      "status": "Active",
                      "metadata": json.dumps({
                          "video_id": video_id,
                          "video_type": video_type,
                          "channel": metadata['channel'],
                          "duration": metadata['duration'],
                          "source": source,
                          "word_count": len(transcript.split())
                      })
                  }
                  
                  r = requests.post(
                      f"{supabase_url}/rest/v1/insights",
                      headers=headers,
                      json=insight,
                      timeout=10
                  )
                  print(f"\nSupabase: {r.status_code}")
              except Exception as e:
                  print(f"Supabase error: {e}")
          
          # Set outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"video_id={video_id}\n")
              f.write(f"source={source}\n")
              f.write(f"length={len(transcript)}\n")
          
          # Save artifact
          with open('transcript.json', 'w') as f:
              json.dump({
                  "video_id": video_id,
                  "title": metadata['title'],
                  "channel": metadata['channel'],
                  "transcript": transcript,
                  "source": source
              }, f, indent=2)
          PYEOF
          
      - uses: actions/upload-artifact@v4
        with:
          name: transcript-${{ steps.transcribe.outputs.video_id }}
          path: transcript.json
          retention-days: 30
