name: ğŸ“º YouTube Transcript Agent V4 (Whisper)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube URL (shorts, regular, live)'
        required: true
        default: 'https://youtube.com/shorts/C2Dl6P7diHw'
      whisper_model:
        description: 'Whisper model'
        required: false
        default: 'base'
        type: choice
        options:
          - tiny
          - base
          - small
      category:
        description: 'Category'
        required: false
        default: 'learning'
        type: choice
        options:
          - learning
          - michael_swim
          - business
          - personal
          - research
      log_to_supabase:
        description: 'Log to Supabase'
        required: false
        default: true
        type: boolean

env:
  SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co

jobs:
  transcribe:
    name: ğŸ¬ Extract YouTube Transcript
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: ğŸ”„ Checkout
        uses: actions/checkout@v4
        
      - name: ğŸ Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: ğŸ“¦ Install Dependencies
        run: |
          pip install youtube-transcript-api yt-dlp httpx requests openai-whisper
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
      - name: ğŸ“º Extract Transcript
        id: transcribe
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          WHISPER_MODEL: ${{ github.event.inputs.whisper_model }}
          CATEGORY: ${{ github.event.inputs.category }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          LOG_TO_SUPABASE: ${{ github.event.inputs.log_to_supabase }}
        run: |
          python3 << 'PYEOF'
          import os, re, json, subprocess, glob, requests, time
          from datetime import datetime, timezone
          
          video_url = os.environ.get('VIDEO_URL', '')
          whisper_model = os.environ.get('WHISPER_MODEL', 'base')
          category = os.environ.get('CATEGORY', 'learning')
          supabase_url = os.environ.get('SUPABASE_URL', '')
          supabase_key = os.environ.get('SUPABASE_KEY', '')
          log_to_supabase = os.environ.get('LOG_TO_SUPABASE', 'true').lower() == 'true'
          
          print(f"{'='*70}")
          print(f"ğŸ“º YOUTUBE TRANSCRIPT AGENT V4 (WHISPER)")
          print(f"{'='*70}")
          print(f"URL: {video_url}")
          
          # Extract video ID
          patterns = [
              r'shorts/([a-zA-Z0-9_-]{11})',
              r'(?:v=|/v/)([a-zA-Z0-9_-]{11})',
              r'youtu\.be/([a-zA-Z0-9_-]{11})',
          ]
          
          video_id = None
          for p in patterns:
              m = re.search(p, video_url)
              if m:
                  video_id = m.group(1)
                  break
          
          if not video_id:
              print("âŒ Invalid URL")
              exit(1)
          
          video_type = "short" if '/shorts/' in video_url else "regular"
          print(f"ğŸ“º Video ID: {video_id} ({video_type})")
          
          # Get metadata via yt-dlp
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0}
          try:
              r = subprocess.run(['yt-dlp', '--dump-json', '--no-download', f"https://www.youtube.com/watch?v={video_id}"],
                                capture_output=True, text=True, timeout=30)
              if r.returncode == 0:
                  d = json.loads(r.stdout)
                  metadata = {"title": d.get('title','Unknown'), "channel": d.get('channel','Unknown'), "duration": d.get('duration',0)}
                  print(f"ğŸ“ Title: {metadata['title'][:60]}")
                  print(f"ğŸ“º Channel: {metadata['channel']}")
                  print(f"â±ï¸ Duration: {metadata['duration']}s")
          except Exception as e:
              print(f"âš ï¸ Metadata error: {e}")
          
          transcript = None
          transcript_source = "none"
          
          # STRATEGY 1: youtube-transcript-api (fastest, FREE)
          print(f"\nğŸ¯ STRATEGY 1: YouTube Transcript API")
          try:
              from youtube_transcript_api import YouTubeTranscriptApi
              api = YouTubeTranscriptApi()
              fetched = api.fetch(video_id)
              transcript = ' '.join([e.text for e in fetched])
              transcript_source = "youtube_api"
              print(f"âœ… Got {len(transcript)} chars from YouTube API")
          except Exception as e:
              print(f"âš ï¸ No captions: {type(e).__name__}")
          
          # STRATEGY 2: yt-dlp auto-subtitles
          if not transcript or len(transcript) < 20:
              print(f"\nğŸ¯ STRATEGY 2: yt-dlp Auto-Subtitles")
              try:
                  subprocess.run(['yt-dlp', '--skip-download', '--write-auto-sub', '--sub-lang', 'en',
                                 '-o', f'/tmp/{video_id}', f"https://www.youtube.com/watch?v={video_id}"],
                                capture_output=True, timeout=60)
                  vtt = glob.glob(f'/tmp/{video_id}*.vtt')
                  if vtt:
                      with open(vtt[0]) as f:
                          lines = [l.strip() for l in f if l.strip() and 'WEBVTT' not in l and '-->' not in l and not l.strip().startswith('<')]
                      transcript = ' '.join(lines)
                      transcript_source = "yt-dlp_subs"
                      print(f"âœ… Got {len(transcript)} chars from yt-dlp subs")
                  else:
                      print("âš ï¸ No auto-subs available")
              except Exception as e:
                  print(f"âš ï¸ yt-dlp subs error: {e}")
          
          # STRATEGY 3: Whisper local transcription (handles no-caption videos)
          if not transcript or len(transcript) < 20:
              print(f"\nğŸ¯ STRATEGY 3: Whisper Transcription ({whisper_model})")
              try:
                  # Download audio
                  print("   Downloading audio...")
                  audio_file = f"/tmp/{video_id}.mp3"
                  result = subprocess.run([
                      'yt-dlp', '-x', '--audio-format', 'mp3',
                      '-o', audio_file,
                      f"https://www.youtube.com/watch?v={video_id}"
                  ], capture_output=True, text=True, timeout=120)
                  
                  # yt-dlp adds extension, find the file
                  audio_files = glob.glob(f"/tmp/{video_id}*")
                  actual_audio = next((f for f in audio_files if f.endswith(('.mp3', '.m4a', '.webm', '.opus'))), None)
                  
                  if actual_audio and os.path.exists(actual_audio):
                      print(f"   Audio: {actual_audio} ({os.path.getsize(actual_audio)} bytes)")
                      
                      # Transcribe with Whisper
                      print(f"   Running Whisper {whisper_model}...")
                      import whisper
                      model = whisper.load_model(whisper_model)
                      result = model.transcribe(actual_audio)
                      transcript = result["text"].strip()
                      transcript_source = f"whisper_{whisper_model}"
                      print(f"âœ… Whisper transcribed {len(transcript)} chars")
                  else:
                      print(f"âš ï¸ Audio download failed")
                      print(f"   Files in /tmp: {audio_files}")
              except Exception as e:
                  print(f"âš ï¸ Whisper error: {e}")
                  import traceback
                  traceback.print_exc()
          
          # Final result
          if not transcript or len(transcript) < 20:
              transcript = "Transcript unavailable - all methods failed"
              transcript_source = "failed"
          
          print(f"\n{'='*70}")
          print(f"ğŸ“Š RESULT: {transcript_source} | {len(transcript)} chars")
          print(f"{'='*70}")
          print(f"\nğŸ“ TRANSCRIPT:\n{'-'*50}")
          print(transcript[:3000])
          
          # Save
          output = {
              "video_id": video_id,
              "video_url": video_url,
              "video_type": video_type,
              "title": metadata['title'],
              "channel": metadata['channel'],
              "duration_seconds": metadata.get('duration', 0),
              "transcript": transcript,
              "transcript_length": len(transcript),
              "word_count": len(transcript.split()),
              "transcript_source": transcript_source,
              "category": category,
              "extracted_at": datetime.now(timezone.utc).isoformat()
          }
          
          with open('transcript.json', 'w') as f:
              json.dump(output, f, indent=2)
          
          # Supabase
          if log_to_supabase and supabase_key and transcript_source != "failed":
              try:
                  headers = {"apikey": supabase_key, "Authorization": f"Bearer {supabase_key}", "Content-Type": "application/json"}
                  insight = {"user_id": 1, "insight_type": "youtube_transcript", "title": f"ğŸ“º {metadata['title'][:80]}",
                            "content": transcript[:10000], "category": category, "source": "youtube_v4_whisper", "priority": 2, "status": "Active"}
                  resp = requests.post(f"{supabase_url}/rest/v1/insights", headers=headers, json=insight, timeout=10)
                  print(f"\nğŸ’¾ Supabase: {resp.status_code}")
              except Exception as e:
                  print(f"âš ï¸ Supabase error: {e}")
          
          # Outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"video_id={video_id}\n")
              f.write(f"transcript_source={transcript_source}\n")
              f.write(f"transcript_length={len(transcript)}\n")
              f.write(f"title={metadata['title'][:50]}\n")
          
          print(f"\nâœ… Done!")
          PYEOF
          
      - name: ğŸ“¤ Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: transcript-${{ steps.transcribe.outputs.video_id }}
          path: transcript.json
          retention-days: 30
          
      - name: ğŸ“Š Summary
        run: |
          echo "## ğŸ“º Transcript Extracted" >> $GITHUB_STEP_SUMMARY
          echo "- **Title:** ${{ steps.transcribe.outputs.title }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** ${{ steps.transcribe.outputs.transcript_source }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Length:** ${{ steps.transcribe.outputs.transcript_length }} chars" >> $GITHUB_STEP_SUMMARY
