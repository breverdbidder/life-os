name: üì∫ YouTube Transcript Agent V4 (With Whisper)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube URL (shorts, regular, live)'
        required: true
        default: 'https://youtube.com/shorts/C2Dl6P7diHw'
      whisper_model:
        description: 'Whisper model'
        required: false
        default: 'base'
        type: choice
        options:
          - tiny
          - base
          - small
      category:
        description: 'Category'
        required: false
        default: 'learning'
        type: choice
        options:
          - learning
          - michael_swim
          - business
          - personal
          - research
      log_to_supabase:
        description: 'Log to Supabase'
        required: false
        default: true
        type: boolean

env:
  SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co

jobs:
  transcribe:
    name: üé¨ Extract YouTube Transcript
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: üîÑ Checkout
        uses: actions/checkout@v4
        
      - name: üêç Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          
      - name: üì¶ Install Dependencies
        run: |
          pip install youtube-transcript-api yt-dlp httpx requests openai-whisper
          sudo apt-get update && sudo apt-get install -y ffmpeg
          
      - name: üì∫ Extract Transcript
        id: transcribe
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          WHISPER_MODEL: ${{ github.event.inputs.whisper_model }}
          CATEGORY: ${{ github.event.inputs.category }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          APIFY_TOKEN: ${{ secrets.APIFY_API_TOKEN }}
          LOG_TO_SUPABASE: ${{ github.event.inputs.log_to_supabase }}
        run: |
          python3 << 'PYEOF'
          import os, re, json, subprocess, glob, requests, time
          from datetime import datetime, timezone
          
          video_url = os.environ.get('VIDEO_URL', '')
          whisper_model = os.environ.get('WHISPER_MODEL', 'base')
          category = os.environ.get('CATEGORY', 'learning')
          supabase_url = os.environ.get('SUPABASE_URL', '')
          supabase_key = os.environ.get('SUPABASE_KEY', '')
          apify_token = os.environ.get('APIFY_TOKEN', '')
          log_to_supabase = os.environ.get('LOG_TO_SUPABASE', 'true').lower() == 'true'
          
          print(f"{'='*70}")
          print(f"üì∫ YOUTUBE TRANSCRIPT AGENT V4 (WITH WHISPER)")
          print(f"{'='*70}")
          print(f"URL: {video_url}")
          
          # Extract video ID
          patterns = [
              r'shorts/([a-zA-Z0-9_-]{11})',
              r'(?:v=|/v/)([a-zA-Z0-9_-]{11})',
              r'youtu\.be/([a-zA-Z0-9_-]{11})',
          ]
          
          video_id = None
          for p in patterns:
              m = re.search(p, video_url)
              if m:
                  video_id = m.group(1)
                  break
          
          if not video_id:
              print("‚ùå Invalid URL")
              exit(1)
          
          video_type = "short" if '/shorts/' in video_url else "regular"
          print(f"üì∫ Video ID: {video_id} ({video_type})")
          
          # Get metadata via yt-dlp
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0}
          try:
              r = subprocess.run(['yt-dlp', '--dump-json', '--no-download', f"https://www.youtube.com/watch?v={video_id}"],
                                capture_output=True, text=True, timeout=30)
              if r.returncode == 0:
                  d = json.loads(r.stdout)
                  metadata = {"title": d.get('title','Unknown'), "channel": d.get('channel','Unknown'), "duration": d.get('duration',0)}
                  print(f"üìù Title: {metadata['title'][:60]}")
                  print(f"üì∫ Channel: {metadata['channel']}")
                  print(f"‚è±Ô∏è Duration: {metadata['duration']}s")
          except Exception as e:
              print(f"‚ö†Ô∏è Metadata error: {e}")
          
          transcript = None
          transcript_source = "none"
          
          # STRATEGY 1: youtube-transcript-api (FREE)
          print(f"\nüéØ STRATEGY 1: YouTube Transcript API")
          try:
              from youtube_transcript_api import YouTubeTranscriptApi
              api = YouTubeTranscriptApi()
              fetched = api.fetch(video_id)
              transcript = ' '.join([e.text for e in fetched])
              transcript_source = "youtube_api"
              print(f"‚úÖ Got {len(transcript)} chars")
          except Exception as e:
              print(f"‚ö†Ô∏è {type(e).__name__}: {e}")
          
          # STRATEGY 2: yt-dlp subtitles (FREE)
          if not transcript or len(transcript) < 20:
              print(f"\nüéØ STRATEGY 2: yt-dlp Subtitles")
              try:
                  subprocess.run(['yt-dlp', '--skip-download', '--write-auto-sub', '--sub-lang', 'en',
                                 '-o', f'/tmp/{video_id}', f"https://www.youtube.com/watch?v={video_id}"],
                                capture_output=True, timeout=60)
                  vtt_files = glob.glob(f'/tmp/{video_id}*.vtt')
                  if vtt_files:
                      with open(vtt_files[0]) as f:
                          lines = [l.strip() for l in f if l.strip() and 'WEBVTT' not in l and '-->' not in l and not l.strip().startswith('<')]
                      transcript = ' '.join(lines)
                      transcript_source = "yt-dlp_subs"
                      print(f"‚úÖ Got {len(transcript)} chars")
                  else:
                      print("‚ö†Ô∏è No subtitle files found")
              except Exception as e:
                  print(f"‚ö†Ô∏è {e}")
          
          # STRATEGY 3: Whisper audio transcription (FREE, local)
          if not transcript or len(transcript) < 20:
              print(f"\nüéØ STRATEGY 3: Whisper Audio Transcription")
              try:
                  # Download audio
                  audio_path = f"/tmp/{video_id}.mp3"
                  dl_result = subprocess.run([
                      'yt-dlp', '-x', '--audio-format', 'mp3', '--audio-quality', '0',
                      '-o', audio_path.replace('.mp3', '.%(ext)s'),
                      f"https://www.youtube.com/watch?v={video_id}"
                  ], capture_output=True, text=True, timeout=120)
                  
                  # Find the downloaded file
                  audio_files = glob.glob(f"/tmp/{video_id}.*")
                  if audio_files:
                      audio_file = audio_files[0]
                      print(f"   üì• Downloaded: {audio_file}")
                      
                      # Run Whisper
                      import whisper
                      print(f"   üé§ Loading Whisper model: {whisper_model}")
                      model = whisper.load_model(whisper_model)
                      print(f"   üé§ Transcribing...")
                      result = model.transcribe(audio_file)
                      transcript = result['text']
                      transcript_source = f"whisper_{whisper_model}"
                      print(f"‚úÖ Got {len(transcript)} chars via Whisper")
                  else:
                      print("‚ö†Ô∏è Audio download failed")
                      print(f"   stdout: {dl_result.stdout[:500]}")
                      print(f"   stderr: {dl_result.stderr[:500]}")
              except Exception as e:
                  print(f"‚ö†Ô∏è Whisper error: {e}")
                  import traceback
                  traceback.print_exc()
          
          # STRATEGY 4: Apify (PAID fallback)
          if (not transcript or len(transcript) < 20) and apify_token:
              print(f"\nüéØ STRATEGY 4: Apify Transcript Scraper")
              try:
                  run_url = "https://api.apify.com/v2/acts/pintostudio~youtube-transcript-scraper/runs?token=" + apify_token
                  payload = {"startUrls": [f"https://www.youtube.com/watch?v={video_id}"], "maxResults": 1}
                  
                  print("   Starting Apify actor...")
                  resp = requests.post(run_url, json=payload, timeout=30)
                  
                  if resp.status_code == 201:
                      run_data = resp.json()
                      run_id = run_data['data']['id']
                      dataset_id = run_data['data']['defaultDatasetId']
                      print(f"   Run ID: {run_id}")
                      
                      for i in range(12):
                          time.sleep(5)
                          status_url = f"https://api.apify.com/v2/actor-runs/{run_id}?token={apify_token}"
                          status_resp = requests.get(status_url, timeout=10)
                          status = status_resp.json()['data']['status']
                          print(f"   Status: {status}")
                          
                          if status == 'SUCCEEDED':
                              dataset_url = f"https://api.apify.com/v2/datasets/{dataset_id}/items?token={apify_token}"
                              results = requests.get(dataset_url, timeout=30).json()
                              
                              if results and len(results) > 0:
                                  item = results[0]
                                  transcript = item.get('transcript', '')
                                  if transcript:
                                      transcript_source = "apify"
                                      metadata['title'] = item.get('videoTitle', metadata['title'])
                                      metadata['channel'] = item.get('channelName', metadata['channel'])
                                      print(f"‚úÖ Got {len(transcript)} chars via Apify")
                              break
                          elif status in ['FAILED', 'ABORTED', 'TIMED-OUT']:
                              print(f"‚ö†Ô∏è Apify run {status}")
                              break
                  else:
                      print(f"‚ö†Ô∏è Apify API error: {resp.status_code}")
                      
              except Exception as e:
                  print(f"‚ö†Ô∏è Apify error: {e}")
          
          # Final result
          if not transcript or len(transcript) < 20:
              transcript = "Transcript unavailable - video may not have captions and audio transcription failed"
              transcript_source = "failed"
          
          print(f"\n{'='*70}")
          print(f"üìä RESULT: {transcript_source} | {len(transcript)} chars")
          print(f"{'='*70}")
          print(f"\nüìù TRANSCRIPT:\n{'-'*50}")
          print(transcript[:3000])
          
          # Save output
          output = {
              "video_id": video_id,
              "video_url": video_url,
              "video_type": video_type,
              "title": metadata['title'],
              "channel": metadata['channel'],
              "duration_seconds": metadata.get('duration', 0),
              "transcript": transcript,
              "transcript_length": len(transcript),
              "word_count": len(transcript.split()),
              "transcript_source": transcript_source,
              "category": category,
              "extracted_at": datetime.now(timezone.utc).isoformat()
          }
          
          with open('transcript.json', 'w') as f:
              json.dump(output, f, indent=2)
          
          # Log to Supabase
          if log_to_supabase and supabase_key and transcript_source != "failed":
              try:
                  headers = {"apikey": supabase_key, "Authorization": f"Bearer {supabase_key}", "Content-Type": "application/json", "Prefer": "return=minimal"}
                  insight = {
                      "user_id": 1, 
                      "insight_type": "youtube_transcript", 
                      "title": f"üì∫ {metadata['title'][:80]}",
                      "content": transcript[:10000], 
                      "category": category, 
                      "source": "youtube_v4", 
                      "priority": 2, 
                      "status": "Active"
                  }
                  r = requests.post(f"{supabase_url}/rest/v1/insights", headers=headers, json=insight, timeout=10)
                  print(f"\nüì§ Supabase: {r.status_code}")
              except Exception as e:
                  print(f"‚ö†Ô∏è Supabase error: {e}")
          
          # GitHub outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"video_id={video_id}\n")
              f.write(f"transcript_source={transcript_source}\n")
              f.write(f"transcript_length={len(transcript)}\n")
          
          print(f"\n‚úÖ Complete!")
          PYEOF
          
      - name: üì§ Upload Artifact
        uses: actions/upload-artifact@v4
        with:
          name: transcript-${{ steps.transcribe.outputs.video_id }}
          path: transcript.json
          retention-days: 30
          
      - name: üìä Summary
        run: |
          echo "## üì∫ Transcript Extracted" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** ${{ steps.transcribe.outputs.transcript_source }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Length:** ${{ steps.transcribe.outputs.transcript_length }} chars" >> $GITHUB_STEP_SUMMARY
