name: üì∫ YouTube Transcript Agent V3 (Fixed)

on:
  workflow_dispatch:
    inputs:
      video_url:
        description: 'YouTube URL (shorts, regular, live, playlist)'
        required: true
        default: 'https://youtube.com/shorts/C2Dl6P7diHw'
      whisper_model:
        description: 'Whisper model for no-caption fallback'
        required: false
        default: 'base'
        type: choice
        options:
          - tiny
          - base
          - small
      category:
        description: 'Category for Supabase logging'
        required: false
        default: 'learning'
        type: choice
        options:
          - learning
          - michael_swim
          - business
          - personal
          - research
      log_to_supabase:
        description: 'Save transcript to Supabase insights'
        required: false
        default: true
        type: boolean

env:
  SUPABASE_URL: https://mocerqjnksmhcjzxrewo.supabase.co

jobs:
  transcribe:
    name: üé¨ Extract YouTube Transcript
    runs-on: ubuntu-latest
    timeout-minutes: 25
    
    steps:
      - name: üîÑ Checkout Repository
        uses: actions/checkout@v4
        
      - name: üêç Setup Python 3.11
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'
          cache: 'pip'
          
      - name: üé¨ Setup FFmpeg
        uses: FedericoCarboni/setup-ffmpeg@v3
        
      - name: üì¶ Install Dependencies
        run: |
          pip install --upgrade pip
          pip install youtube-transcript-api yt-dlp httpx requests webvtt-py
          pip install openai-whisper torch
          
      - name: üì∫ Extract Transcript (Multi-Strategy)
        id: transcribe
        env:
          VIDEO_URL: ${{ github.event.inputs.video_url }}
          WHISPER_MODEL: ${{ github.event.inputs.whisper_model }}
          CATEGORY: ${{ github.event.inputs.category }}
          SUPABASE_KEY: ${{ secrets.SUPABASE_SERVICE_KEY }}
          LOG_TO_SUPABASE: ${{ github.event.inputs.log_to_supabase }}
        run: |
          python3 << 'PYEOF'
          import os
          import re
          import json
          import subprocess
          import glob
          import requests
          from datetime import datetime, timezone
          
          video_url = os.environ.get('VIDEO_URL', '')
          whisper_model = os.environ.get('WHISPER_MODEL', 'base')
          category = os.environ.get('CATEGORY', 'learning')
          supabase_url = os.environ.get('SUPABASE_URL', '')
          supabase_key = os.environ.get('SUPABASE_KEY', '')
          log_to_supabase = os.environ.get('LOG_TO_SUPABASE', 'true').lower() == 'true'
          
          print(f"{'='*70}")
          print(f"üì∫ YOUTUBE TRANSCRIPT AGENT V3 - FIXED")
          print(f"{'='*70}")
          print(f"URL: {video_url}")
          print(f"Category: {category}")
          print(f"Whisper Model: {whisper_model}")
          
          # Extract video ID
          patterns = [
              r'shorts/([a-zA-Z0-9_-]{11})',
              r'live/([a-zA-Z0-9_-]{11})',
              r'(?:v=|/v/)([a-zA-Z0-9_-]{11})',
              r'youtu\.be/([a-zA-Z0-9_-]{11})',
              r'embed/([a-zA-Z0-9_-]{11})',
          ]
          
          video_id = None
          for pattern in patterns:
              match = re.search(pattern, video_url)
              if match:
                  video_id = match.group(1)
                  break
          
          if not video_id:
              print("‚ùå Invalid YouTube URL")
              exit(1)
          
          video_type = "short" if '/shorts/' in video_url else ("live" if '/live/' in video_url else "regular")
          print(f"\nüì∫ Video ID: {video_id}")
          print(f"üìå Type: {video_type}")
          
          # Get metadata
          print(f"\nüîç Fetching metadata...")
          metadata = {"title": "Unknown", "channel": "Unknown", "duration": 0, "view_count": 0}
          
          try:
              # Use full URL for yt-dlp
              full_url = f"https://www.youtube.com/watch?v={video_id}"
              result = subprocess.run(
                  ['yt-dlp', '--dump-json', '--no-download', '--no-warnings', full_url],
                  capture_output=True, text=True, timeout=60
              )
              if result.returncode == 0 and result.stdout.strip():
                  data = json.loads(result.stdout.strip())
                  metadata = {
                      "title": data.get('title', 'Unknown'),
                      "channel": data.get('channel', data.get('uploader', 'Unknown')),
                      "duration": int(data.get('duration', 0)),
                      "view_count": int(data.get('view_count', 0)),
                  }
                  print(f"   üìù Title: {metadata['title'][:60]}")
                  print(f"   üë§ Channel: {metadata['channel']}")
                  print(f"   ‚è±Ô∏è Duration: {metadata['duration']}s")
          except Exception as e:
              print(f"‚ö†Ô∏è Metadata error: {e}")
          
          transcript = None
          transcript_source = "none"
          language = "unknown"
          
          # STRATEGY 1: youtube-transcript-api
          print(f"\n{'='*50}")
          print(f"üéØ STRATEGY 1: YouTube Transcript API")
          print(f"{'='*50}")
          
          try:
              from youtube_transcript_api import YouTubeTranscriptApi
              api = YouTubeTranscriptApi()
              fetched = api.fetch(video_id)
              transcript = ' '.join([entry.text for entry in fetched])
              transcript_source = "youtube_transcript_api"
              language = "en"
              print(f"‚úÖ SUCCESS: {len(transcript)} chars")
          except Exception as e:
              print(f"‚ö†Ô∏è Failed: {type(e).__name__}")
          
          # STRATEGY 2: yt-dlp subtitles
          if not transcript or len(transcript) < 20:
              print(f"\n{'='*50}")
              print(f"üéØ STRATEGY 2: yt-dlp Subtitles")
              print(f"{'='*50}")
              
              try:
                  full_url = f"https://www.youtube.com/watch?v={video_id}"
                  cmd = [
                      'yt-dlp', '--skip-download',
                      '--write-auto-sub', '--write-sub',
                      '--sub-lang', 'en,en-US,en-GB',
                      '--sub-format', 'vtt',
                      '-o', f'/tmp/{video_id}',
                      full_url
                  ]
                  subprocess.run(cmd, capture_output=True, timeout=120)
                  
                  vtt_files = glob.glob(f'/tmp/{video_id}*.vtt')
                  if vtt_files:
                      with open(vtt_files[0], 'r') as f:
                          content = f.read()
                      lines = []
                      for line in content.split('\n'):
                          line = line.strip()
                          if not line or 'WEBVTT' in line or '-->' in line:
                              continue
                          if line.startswith('Kind:') or line.startswith('Language:'):
                              continue
                          if re.match(r'^\d+$', line):
                              continue
                          line = re.sub(r'<[^>]+>', '', line)
                          if line and line not in lines[-1:]:
                              lines.append(line)
                      transcript = ' '.join(lines)
                      transcript_source = "yt-dlp_subtitles"
                      language = "en"
                      print(f"‚úÖ SUCCESS: {len(transcript)} chars")
                  else:
                      print("‚ö†Ô∏è No subtitle files found")
              except Exception as e:
                  print(f"‚ö†Ô∏è Failed: {e}")
          
          # STRATEGY 3: Whisper (FIXED for Shorts)
          if not transcript or len(transcript) < 20:
              print(f"\n{'='*50}")
              print(f"üéØ STRATEGY 3: Whisper ({whisper_model})")
              print(f"{'='*50}")
              
              try:
                  import whisper
                  
                  # FIXED: Use proper URL and format for shorts
                  full_url = f"https://www.youtube.com/watch?v={video_id}"
                  audio_path = f"/tmp/audio_{video_id}.mp3"
                  
                  print("üîä Downloading audio...")
                  cmd = [
                      'yt-dlp',
                      '-x',
                      '--audio-format', 'mp3',
                      '--audio-quality', '0',
                      '-o', audio_path.replace('.mp3', '.%(ext)s'),
                      '--no-warnings',
                      '--force-overwrites',
                      full_url
                  ]
                  
                  result = subprocess.run(cmd, capture_output=True, text=True, timeout=300)
                  print(f"   yt-dlp return code: {result.returncode}")
                  
                  # Check for any audio files
                  audio_files = glob.glob(f'/tmp/audio_{video_id}.*')
                  print(f"   Audio files found: {audio_files}")
                  
                  if audio_files:
                      audio_file = audio_files[0]
                      print(f"üé§ Transcribing {audio_file}...")
                      
                      model = whisper.load_model(whisper_model)
                      result = model.transcribe(audio_file)
                      
                      transcript = result['text'].strip()
                      transcript_source = f"whisper_{whisper_model}"
                      language = result.get('language', 'unknown')
                      
                      print(f"‚úÖ SUCCESS: {len(transcript)} chars")
                      print(f"   Language: {language}")
                      print(f"   Preview: {transcript[:200]}...")
                      
                      os.remove(audio_file)
                  else:
                      print("‚ö†Ô∏è No audio file created")
                      if result.stderr:
                          print(f"   stderr: {result.stderr[:500]}")
                      
              except Exception as e:
                  print(f"‚ö†Ô∏è Whisper failed: {e}")
                  import traceback
                  traceback.print_exc()
          
          # Final result
          if not transcript:
              transcript = "Transcript unavailable"
              transcript_source = "failed"
          
          print(f"\n{'='*70}")
          print(f"üìä FINAL RESULT")
          print(f"{'='*70}")
          print(f"   Source: {transcript_source}")
          print(f"   Language: {language}")
          print(f"   Characters: {len(transcript)}")
          print(f"   Words: {len(transcript.split())}")
          print(f"\nüìù TRANSCRIPT:")
          print(f"{'-'*50}")
          print(transcript[:3000])
          
          # Save output
          output = {
              "video_id": video_id,
              "video_url": video_url,
              "video_type": video_type,
              "title": metadata.get('title', 'Unknown'),
              "channel": metadata.get('channel', 'Unknown'),
              "duration_seconds": metadata.get('duration', 0),
              "view_count": metadata.get('view_count', 0),
              "transcript": transcript[:100000],
              "transcript_length": len(transcript),
              "word_count": len(transcript.split()),
              "transcript_source": transcript_source,
              "language": language,
              "category": category,
              "extracted_at": datetime.now(timezone.utc).isoformat()
          }
          
          with open('transcript.json', 'w') as f:
              json.dump(output, f, indent=2, ensure_ascii=False)
          
          print(f"\nüíæ Saved transcript.json")
          
          # Log to Supabase if successful
          if log_to_supabase and supabase_key and transcript_source != "failed":
              print(f"\nüì§ Logging to Supabase...")
              try:
                  headers = {
                      "apikey": supabase_key,
                      "Authorization": f"Bearer {supabase_key}",
                      "Content-Type": "application/json"
                  }
                  insight = {
                      "user_id": 1,
                      "insight_type": "youtube_transcript",
                      "title": f"üì∫ {metadata['title'][:80]}",
                      "content": transcript[:10000],
                      "category": category,
                      "source": "youtube_transcript_v3",
                      "priority": 2,
                      "status": "Active"
                  }
                  resp = requests.post(f"{supabase_url}/rest/v1/insights", headers=headers, json=insight)
                  print(f"   Supabase: {resp.status_code}")
              except Exception as e:
                  print(f"   Supabase error: {e}")
          
          # GitHub outputs
          with open(os.environ['GITHUB_OUTPUT'], 'a') as f:
              f.write(f"video_id={video_id}\n")
              f.write(f"transcript_source={transcript_source}\n")
              f.write(f"transcript_length={len(transcript)}\n")
          
          print(f"\n‚úÖ Complete!")
          PYEOF
          
      - name: üì§ Upload Transcript Artifact
        uses: actions/upload-artifact@v4
        with:
          name: transcript-${{ steps.transcribe.outputs.video_id }}
          path: transcript.json
          retention-days: 30
          
      - name: üìä Job Summary
        run: |
          echo "## üì∫ YouTube Transcript Extracted" >> $GITHUB_STEP_SUMMARY
          echo "" >> $GITHUB_STEP_SUMMARY
          echo "- **Video ID:** ${{ steps.transcribe.outputs.video_id }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Source:** ${{ steps.transcribe.outputs.transcript_source }}" >> $GITHUB_STEP_SUMMARY
          echo "- **Length:** ${{ steps.transcribe.outputs.transcript_length }} chars" >> $GITHUB_STEP_SUMMARY
